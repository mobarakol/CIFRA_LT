{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10H.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSdW7WWnpWSwRfiotrbKqG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/CIFRA_LT/blob/main/CIFAR_10H.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cloning repository of CIFAR-10H Annotation\n",
        "paper: Human uncertainty makes classification more robust (https://arxiv.org/pdf/1908.07086.pdf)"
      ],
      "metadata": {
        "id": "_vL2RMWddkaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KrQIqW6_NYl",
        "outputId": "af0d03b6-8d42-4e76-cf0f-7eb3db47ffcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cifar-10h'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 48\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n",
            "/content/cifar-10h\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jcpeterson/cifar-10h\n",
        "%cd cifar-10h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main script"
      ],
      "metadata": {
        "id": "qNN4TybGd2Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "def seed_everything(seed=12):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "parser = argparse.ArgumentParser(description='CIFAR-10H Training')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--lr_schedule', default=0, type=int, help='lr scheduler')\n",
        "parser.add_argument('--batch_size', default=1024, type=int, help='batch size')\n",
        "parser.add_argument('--test_batch_size', default=2048, type=int, help='batch size')\n",
        "parser.add_argument('--num_epoch', default=10, type=int, help='epoch number')\n",
        "parser.add_argument('--num_classes', type=int, default=10, help='number classes')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "def train(model, trainloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets, ad) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "NN371ewSCWX7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10H dataloader"
      ],
      "metadata": {
        "id": "WHKUA3yBd87G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "class CIFAR10H(torchvision.datasets.CIFAR10):\n",
        "\n",
        "    def __init__(self, root,  rand_number=0, train=False, transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        super(CIFAR10H, self).__init__(root, train, transform, target_transform, download) \n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.ad = np.load(os.path.join(root,'cifar10h-probs.npy'))\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "        ad = self.ad[index]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "        return img, target, ad"
      ],
      "metadata": {
        "id": "z4uiWMiyCkjk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run script"
      ],
      "metadata": {
        "id": "wRQEQIdaerKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "mean_cifar10, std_cifar10 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "            transforms.Normalize(mean_cifar10, std_cifar10), ])\n",
        "transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_cifar10, std_cifar10),])\n",
        "\n",
        "train_dataset = CIFAR10H(root='./data', train=False, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_test)\n",
        "print('train samples:',len(train_dataset), 'test samples:',len(test_dataset))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "model = models.resnet34(pretrained=True).to(device)\n",
        "model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "best_epoch, best_acc = 0.0, 0\n",
        "for epoch in range(args.num_epoch):\n",
        "    train(model, train_loader, criterion, optimizer)\n",
        "    accuracy = test(model, test_loader)\n",
        "    if accuracy > best_acc:\n",
        "        patience = 0\n",
        "        best_acc = accuracy\n",
        "        best_epoch = epoch\n",
        "        best_model = copy.deepcopy(model)\n",
        "        torch.save(best_model.state_dict(), 'best_model_cifar10h.pth.tar')\n",
        "    print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f}'.format(\n",
        "            epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rpOrSuEFY2N",
        "outputId": "9fa6a443-ffee-4a06-f51f-bc8ad760b0f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "train samples: 10000 test samples: 50000\n",
            "epoch: 0  acc: 0.3635  best epoch: 0  best acc: 0.3635\n",
            "epoch: 1  acc: 0.4829  best epoch: 1  best acc: 0.4829\n",
            "epoch: 2  acc: 0.5996  best epoch: 2  best acc: 0.5996\n",
            "epoch: 3  acc: 0.6816  best epoch: 3  best acc: 0.6816\n",
            "epoch: 4  acc: 0.6947  best epoch: 4  best acc: 0.6947\n",
            "epoch: 5  acc: 0.7070  best epoch: 5  best acc: 0.7070\n",
            "epoch: 6  acc: 0.7464  best epoch: 6  best acc: 0.7464\n",
            "epoch: 7  acc: 0.7352  best epoch: 6  best acc: 0.7464\n",
            "epoch: 8  acc: 0.7429  best epoch: 6  best acc: 0.7464\n",
            "epoch: 9  acc: 0.7674  best epoch: 9  best acc: 0.7674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "krBAqR41UU7p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}